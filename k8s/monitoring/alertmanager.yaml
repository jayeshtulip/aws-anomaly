apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: 'YOUR_SLACK_WEBHOOK_URL'  # Replace with your Slack webhook

    route:
      group_by: ['alertname', 'severity']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'default'
      routes:
        - match:
            severity: critical
          receiver: 'pagerduty-critical'
          continue: true
        
        - match:
            severity: critical
          receiver: 'slack-critical'
        
        - match:
            severity: warning
          receiver: 'slack-warnings'
        
        - match:
            alertname: DataDriftDetected
          receiver: 'webhook-retrain'
        
        - match:
            alertname: ModelAccuracyDegraded
          receiver: 'webhook-retrain'

    receivers:
      - name: 'default'
        slack_configs:
          - channel: '#ml-alerts'
            title: 'Alert: {{ .GroupLabels.alertname }}'
            text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
      
      - name: 'slack-critical'
        slack_configs:
          - channel: '#ml-critical'
            title: 'üî¥ CRITICAL: {{ .GroupLabels.alertname }}'
            text: |
              *Summary:* {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
              *Description:* {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
              *Runbook:* {{ range .Alerts }}{{ .Annotations.runbook }}{{ end }}
            color: 'danger'
            send_resolved: true
      
      - name: 'slack-warnings'
        slack_configs:
          - channel: '#ml-ops'
            title: '‚ö†Ô∏è WARNING: {{ .GroupLabels.alertname }}'
            text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
            color: 'warning'
      
      - name: 'pagerduty-critical'
        pagerduty_configs:
          - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'  # Replace
            description: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
      
      - name: 'webhook-retrain'
        webhook_configs:
          - url: 'http://retrain-webhook:5000/trigger'
            send_resolved: false
            http_config:
              bearer_token: 'YOUR_WEBHOOK_SECRET'  # Replace

    inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'instance']
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      containers:
        - name: alertmanager
          image: prom/alertmanager:latest
          args:
            - '--config.file=/etc/alertmanager/alertmanager.yml'
            - '--storage.path=/alertmanager'
            - '--cluster.listen-address=0.0.0.0:9094'
          ports:
            - containerPort: 9093
              name: web
            - containerPort: 9094
              name: cluster
          volumeMounts:
            - name: config
              mountPath: /etc/alertmanager
            - name: data
              mountPath: /alertmanager
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 256Mi
      volumes:
        - name: config
          configMap:
            name: alertmanager-config
        - name: data
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  selector:
    app: alertmanager
  ports:
    - port: 9093
      targetPort: 9093
      name: web
    - port: 9094
      targetPort: 9094
      name: cluster
  type: ClusterIP